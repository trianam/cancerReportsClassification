{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funPytorch as fun\n",
    "import configurationsMulticlass\n",
    "import configurations\n",
    "import math\n",
    "import time\n",
    "import pandas\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score \n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatePred(conf):\n",
    "    model,optim = fun.loadModel(conf, \"cuda:0\")\n",
    "    X, y, train, valid, test = fun.processData(conf)\n",
    "    _, _, _, _, _, _, _, _, y, yp = fun.runTest(conf, model, X, y, test)\n",
    "    return y,yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateValidAcc(conf, verbose=False):\n",
    "    model,optim = fun.loadModel(conf, \"cuda:0\")\n",
    "    X, y, train, valid, test = fun.processData(conf)\n",
    "    _, acc, _, _, _, _, _, _, _, _ = fun.runTest(conf, model, X, y, valid, verbose)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateTestAcc(conf, verbose=False):\n",
    "    model,optim = fun.loadModel(conf, \"cuda:0\")\n",
    "    X, y, train, valid, test = fun.processData(conf)\n",
    "    _, acc, _, _, _, _, _, _, _, _ = fun.runTest(conf, model, X, y, test, verbose)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmultiCNNp/128/64/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "test_loss: 0.5902 - test_acc: 89.1048\n",
      "MAPs: 0.9285 - MAPc: 0.3966\n",
      "acc: 0.8910 - kappa: 0.8771\n",
      "accT3: 0.9593 - accT5: 0.9758\n",
      "f1micro: 0.8910 - f1macro: 0.5207\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] = calculatePred(configurationsMulticlass.configTmultiCNNpBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionsCNN-Asite.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morpho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTMmultiCNNp/128/64/best.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "test_loss: 0.7399 - test_acc: 82.6793\n",
      "MAPs: 0.8875 - MAPc: 0.2997\n",
      "acc: 0.8268 - kappa: 0.8056\n",
      "accT3: 0.9388 - accT5: 0.9615\n",
      "f1micro: 0.8268 - f1macro: 0.4242\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] = calculatePred(configurationsMulticlass.configTMmultiCNNpBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionsCNN-Amorpho.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmultiCNN/16/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "16: 0.8970881765880004\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmultiCNN/32/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "32: 0.9058353880474346\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmultiCNN/64/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "64: 0.9078901021486439\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmultiCNN/128/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "128: 0.9077139837971117\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmultiCNN/256/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "256: 0.9090055183750146\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmultiCNN/512/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "512: 0.9035458494775156\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "for nk in configurationsMulticlass.configTmultiCNN:\n",
    "    acc = calculateValidAcc(configurationsMulticlass.configTmultiCNN[nk])\n",
    "    print(\"{}: {}\".format(nk, acc))\n",
    "    print(\"=================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmultiCNNnd/16/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "16: 0.8978513561113068\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmultiCNNnd/32/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "32: 0.9020194904309029\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmultiCNNnd/64/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "64: 0.9013737231419514\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmultiCNNnd/128/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "128: 0.8973817071738875\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmultiCNNnd/256/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "256: 0.8957966420100975\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmultiCNNnd/512/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "512: 0.8995538335094517\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "for nk in configurationsMulticlass.configTmultiCNNnd:\n",
    "    acc = calculateValidAcc(configurationsMulticlass.configTmultiCNNnd[nk])\n",
    "    print(\"{}: {}\".format(nk, acc))\n",
    "    print(\"=================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmultiCNN/256/epoch{}.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "test_loss: 0.6423 - test_acc: 88.6176\n",
      "MAPs: 0.9249 - MAPc: 0.3486\n",
      "acc: 0.8862 - kappa: 0.8717\n",
      "accT3: 0.9578 - accT5: 0.9729\n",
      "f1micro: 0.8862 - f1macro: 0.5028\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] = calculatePred(configurationsMulticlass.configTmultiCNN[256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(p, open(\"predictionsCNN-Asite.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morpho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTMmultiCNN/16/best.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "16: 0.8429859188122312\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTMmultiCNN/32/best.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "32: 0.8548282566429034\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTMmultiCNN/64/best.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "64: 0.8557709303010664\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTMmultiCNN/128/best.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "128: 0.858186531550109\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTMmultiCNN/256/best.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "256: 0.8563011842337831\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTMmultiCNN/512/best.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "512: 0.8513521475284275\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTMmultiCNN/1024/best.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "1024: 0.8491722146939257\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTMmultiCNN/2048/best.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "2048: 0.846403110823072\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "for nk in configurationsMulticlass.configTMmultiCNN:\n",
    "    acc = calculateValidAcc(configurationsMulticlass.configTMmultiCNN[nk])\n",
    "    print(\"{}: {}\".format(nk, acc))\n",
    "    print(\"=================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTMmultiCNN/128/best.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "test_loss: 0.8292 - test_acc: 81.5175\n",
      "MAPs: 0.8782 - MAPc: 0.2413\n",
      "acc: 0.8152 - kappa: 0.7928\n",
      "accT3: 0.9310 - accT5: 0.9531\n",
      "f1micro: 0.8152 - f1macro: 0.3874\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] = calculatePred(configurationsMulticlass.configTMmultiCNN[128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(p, open(\"predictionsCNN-Amorpho.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULATE HYPERPARAMETERS WITH TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/40/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/40/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/40/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/40/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/50/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/50/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/50/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/50/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/70/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/70/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/70/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/70/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/80/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/80/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/80/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/80/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/90/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/90/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/90/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/90/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/100/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/100/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/100/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/100/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/200/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/200/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/200/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/200/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/300/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/300/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/300/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/300/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "rows = []\n",
    "columns = []\n",
    "for vs in configurationsMulticlass.configTmulti1GloveVecSizeWinSize:\n",
    "    rows.append(vs)\n",
    "    currAccuracies = []\n",
    "    for ws in configurationsMulticlass.configTmulti1GloveVecSizeWinSize[vs]:\n",
    "        currAccuracies.append(calculateTestAcc(configurationsMulticlass.configTmulti1GloveVecSizeWinSize[vs][ws]))\n",
    "        if len(accuracies) == 0:\n",
    "            columns.append(ws)\n",
    "    accuracies.append(currAccuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8907543293219842,\n",
       "  0.8912826533607279,\n",
       "  0.8960375697094218,\n",
       "  0.9002054593484003],\n",
       " [0.8925154094511301,\n",
       "  0.8933372468447315,\n",
       "  0.8977986498385676,\n",
       "  0.9007337833871442],\n",
       " [0.8922805987672439,\n",
       "  0.8958027590255356,\n",
       "  0.9006750807161726,\n",
       "  0.8990901085999413],\n",
       " [0.8916348693865571,\n",
       "  0.897387731141767,\n",
       "  0.9007924860581157,\n",
       "  0.9009098914000587],\n",
       " [0.8923393014382155,\n",
       "  0.8974464338127385,\n",
       "  0.9013795127678309,\n",
       "  0.9002641620193719],\n",
       " [0.8966832990901086,\n",
       "  0.899618432638685,\n",
       "  0.9007924860581157,\n",
       "  0.8987378925741121],\n",
       " [0.8952157323158204,\n",
       "  0.9009098914000587,\n",
       "  0.9009685940710302,\n",
       "  0.9002054593484003],\n",
       " [0.895509245670678,\n",
       "  0.9021426474904608,\n",
       "  0.9027883768711477,\n",
       "  0.904490754329322]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesNp = np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89075433, 0.89128265, 0.89603757, 0.90020546],\n",
       "       [0.89251541, 0.89333725, 0.89779865, 0.90073378],\n",
       "       [0.8922806 , 0.89580276, 0.90067508, 0.89909011],\n",
       "       [0.89163487, 0.89738773, 0.90079249, 0.90090989],\n",
       "       [0.8923393 , 0.89744643, 0.90137951, 0.90026416],\n",
       "       [0.8966833 , 0.89961843, 0.90079249, 0.89873789],\n",
       "       [0.89521573, 0.90090989, 0.90096859, 0.90020546],\n",
       "       [0.89550925, 0.90214265, 0.90278838, 0.90449075]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuraciesNp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/40/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "40: 0.8977986498385676\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/50/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "50: 0.8994423246257705\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/70/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "70: 0.8992662166128559\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/80/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "80: 0.8990314059289698\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/90/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "90: 0.9016143234517171\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/100/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "100: 0.9009098914000587\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/200/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "200: 0.8981508658643969\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/300/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "300: 0.9030818902260053\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "for vs in configurationsMulticlass.configTmulti1GloveVecSize:\n",
    "    acc = calculateTestAcc(configurationsMulticlass.configTmulti1GloveVecSize[vs])\n",
    "    print(\"{}: {}\".format(vs, acc))\n",
    "    print(\"=================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmulti1GloveWinSize/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "2: 0.8916935720575286\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveWinSize/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "5: 0.8970355151159378\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveWinSize/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "10: 0.900498972703258\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveWinSize/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "20: 0.8989140005870268\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "for ws in configurationsMulticlass.configTmulti1GloveWinSize:\n",
    "    acc = calculateTestAcc(configurationsMulticlass.configTmulti1GloveWinSize[ws])\n",
    "    print(\"{}: {}\".format(ws, acc))\n",
    "    print(\"=================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmulti1Flair/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "test_loss: 0.4354 - test_acc: 89.8914\n",
      "MAPs: 0.9348 - MAPc: 0.5527\n",
      "acc: 0.8989 - kappa: 0.8861\n",
      "accT3: 0.9647 - accT5: 0.9802\n",
      "f1micro: 0.8989 - f1macro: 0.5587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([[ -2.5707445 ,  -9.100924  ,  -7.312047  , ...,  -2.761337  ,\n",
       "          -4.2915835 ,  -4.1164207 ],\n",
       "        [ -7.7655563 ,  -8.871245  ,  -4.1409335 , ...,  -3.5212982 ,\n",
       "         -11.382654  ,  -1.7438542 ],\n",
       "        [-14.147037  , -10.673989  , -11.131611  , ...,  -3.5333116 ,\n",
       "          -0.205113  ,  -0.82649136],\n",
       "        ...,\n",
       "        [-13.958148  , -10.009639  , -12.896826  , ...,  -6.4884033 ,\n",
       "          -6.006666  ,  -2.082936  ],\n",
       "        [-19.949125  , -13.060993  , -10.419918  , ...,  -7.574818  ,\n",
       "         -10.195772  ,  -2.6577365 ],\n",
       "        [-16.946983  , -13.418258  , -16.110233  , ...,  -7.245941  ,\n",
       "          -8.225455  ,  -2.0414028 ]], dtype=float32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculatePred(configurationsMulticlass.configTmulti1Flair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Site Vector and Window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/40/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/40/5/best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trianam/miniconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/40/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/40/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/50/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/50/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/50/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/50/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/70/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/70/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/70/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/70/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/80/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/80/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/80/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/80/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/90/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/90/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/90/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/90/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/100/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/100/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/100/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/100/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/200/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/200/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/200/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/200/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/300/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/300/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/300/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/300/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "rows = []\n",
    "columns = []\n",
    "for vs in configurationsMulticlass.configTmulti1GloveVecSizeWinSize:\n",
    "    rows.append(vs)\n",
    "    currAccuracies = []\n",
    "    for ws in configurationsMulticlass.configTmulti1GloveVecSizeWinSize[vs]:\n",
    "        currAccuracies.append(calculateValidAcc(configurationsMulticlass.configTmulti1GloveVecSizeWinSize[vs][ws]))\n",
    "        if len(accuracies) == 0:\n",
    "            columns.append(ws)\n",
    "    accuracies.append(currAccuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.9112363508277562,\n",
       "  0.9119995303510626,\n",
       "  0.9162850769050135,\n",
       "  0.9174591992485617],\n",
       " [0.9115298814136433,\n",
       "  0.9174591992485617,\n",
       "  0.9148174239755783,\n",
       "  0.9208641540448514],\n",
       " [0.9128801221087237,\n",
       "  0.9180462604203358,\n",
       "  0.9201596806387226,\n",
       "  0.9195139133497711],\n",
       " [0.9122343548197722,\n",
       "  0.9159915463191265,\n",
       "  0.9183984971234003,\n",
       "  0.918926852177997],\n",
       " [0.9144651872725138,\n",
       "  0.9159328402019491,\n",
       "  0.9174004931313843,\n",
       "  0.9197487378184807],\n",
       " [0.9141716566866267,\n",
       "  0.9179875543031584,\n",
       "  0.9196313255841259,\n",
       "  0.9183984971234003],\n",
       " [0.9161676646706587,\n",
       "  0.9186920277092873,\n",
       "  0.9186333215921099,\n",
       "  0.9229775742632382],\n",
       " [0.9170482564283199, 0.919924856170013, 0.9211576846307385, 0.92180345191969]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesNp = np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91123635, 0.91199953, 0.91628508, 0.9174592 ],\n",
       "       [0.91152988, 0.9174592 , 0.91481742, 0.92086415],\n",
       "       [0.91288012, 0.91804626, 0.92015968, 0.91951391],\n",
       "       [0.91223435, 0.91599155, 0.9183985 , 0.91892685],\n",
       "       [0.91446519, 0.91593284, 0.91740049, 0.91974874],\n",
       "       [0.91417166, 0.91798755, 0.91963133, 0.9183985 ],\n",
       "       [0.91616766, 0.91869203, 0.91863332, 0.92297757],\n",
       "       [0.91704826, 0.91992486, 0.92115768, 0.92180345]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuraciesNp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 50, 70, 80, 90, 100, 200, 300]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows #vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 10, 20]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns #ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSizeWinSize/200/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "test_loss: 0.4529 - test_acc: 90.0205\n",
      "MAPs: 0.9353 - MAPc: 0.5827\n",
      "acc: 0.9002 - kappa: 0.8876\n",
      "accT3: 0.9649 - accT5: 0.9787\n",
      "f1micro: 0.9002 - f1macro: 0.5871\n"
     ]
    }
   ],
   "source": [
    "calculatePred(configurationsMulticlass.configTmulti1GloveVecSizeWinSize[200][20]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Site Vector Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/40/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "40: 0.9174004931313843\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/50/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "50: 0.9164611952565457\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/70/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "70: 0.9191616766467066\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/80/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "80: 0.9213338029822707\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/90/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "90: 0.9218621580368674\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/100/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "100: 0.9191029705295292\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/200/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "200: 0.9202770928730774\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveVecSize/300/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "300: 0.9218621580368674\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "for vs in configurationsMulticlass.configTmulti1GloveVecSize:\n",
    "    acc = calculateValidAcc(configurationsMulticlass.configTmulti1GloveVecSize[vs])\n",
    "    print(\"{}: {}\".format(vs, acc))\n",
    "    print(\"=================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Site Window Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmulti1GloveWinSize/2/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "2: 0.9122343548197722\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveWinSize/5/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "5: 0.9168134319596102\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveWinSize/10/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "10: 0.9186920277092873\n",
      "=================\n",
      "Loading modelsPytorchMulticlass/confTmulti1GloveWinSize/20/best.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "20: 0.9190442644123518\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "for ws in configurationsMulticlass.configTmulti1GloveWinSize:\n",
    "    acc = calculateValidAcc(configurationsMulticlass.configTmulti1GloveWinSize[ws])\n",
    "    print(\"{}: {}\".format(ws, acc))\n",
    "    print(\"=================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTbaseMulti/2/256/GRU/epoch4.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "test_loss: 0.4549 - test_acc: 89.7681\n",
      "MAPs: 0.9331 - MAPc: 0.5563\n",
      "acc: 0.8977 - kappa: 0.8848\n",
      "accT3: 0.9636 - accT5: 0.9764\n",
      "f1micro: 0.8977 - f1macro: 0.5543\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] = calculatePred(configurationsMulticlass.configTbaseMultiBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionGRU-Asite.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTImulti2/2/128/epoch35.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "test_loss: 3.3127 - test_acc: 87.9190\n",
      "MAPs: 0.9190 - MAPc: 0.4259\n",
      "acc: 0.8792 - kappa: 0.8637\n",
      "accT3: 0.9533 - accT5: 0.9610\n",
      "f1micro: 0.8792 - f1macro: 0.4197\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] = calculatePred(configurationsMulticlass.configTImulti2best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionMAXi-Asite.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confH/64/2/1024/best.pt\n",
      "         reprocessed line 85170/85170           \n",
      "test_loss: 0.4304 - test_acc: 89.7975\n",
      "MAPs: 0.9329 - MAPc: 0.5273\n",
      "acc: 0.8980 - kappa: 0.8851\n",
      "accT3: 0.9611 - accT5: 0.9773\n",
      "f1micro: 0.8980 - f1macro: 0.5567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trianam/miniconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] =  calculatePred(configurationsMulticlass.configHbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionMAXh-Asite.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confHS/128/1/1024/128/best.pt\n",
      "         reprocessed line 85170/85170           \n",
      "test_loss: 0.4525 - test_acc: 89.8268\n",
      "MAPs: 0.9329 - MAPc: 0.5398\n",
      "acc: 0.8983 - kappa: 0.8855\n",
      "accT3: 0.9617 - accT5: 0.9760\n",
      "f1micro: 0.8983 - f1macro: 0.5479\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] =  calculatePred(configurationsMulticlass.configHSbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionATTh-Asite.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTSmulti1/128/1/512/256/epoch8.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "test_loss: 0.4783 - test_acc: 90.0792\n",
      "MAPs: 0.9341 - MAPc: 0.5659\n",
      "acc: 0.9008 - kappa: 0.8883\n",
      "accT3: 0.9607 - accT5: 0.9749\n",
      "f1micro: 0.9008 - f1macro: 0.5766\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] =  calculatePred(configurationsMulticlass.configTSmulti1best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionATT-Asite.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTmulti1/128/1/512/epoch5.pt\n",
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n",
      "test_loss: 0.4235 - test_acc: 90.2436\n",
      "MAPs: 0.9369 - MAPc: 0.5680\n",
      "acc: 0.9024 - kappa: 0.8901\n",
      "accT3: 0.9658 - accT5: 0.9797\n",
      "f1micro: 0.9024 - f1macro: 0.5887\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] =  calculatePred(configurationsMulticlass.configTmulti1best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionMAX-Asite.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['SVM'] = calculateMetrics(pickle.load(open(\"predictionsSVM-Asite.p\", 'rb')), valuesS, toRemoveS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['XGBoost'] = calculateMetrics(pickle.load(open(\"predictionsXGBoost-Asite.p\", 'rb')), valuesS, toRemoveS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['BERT'] = calculateMetrics(pickle.load(open(\"../../bert/predictionsBERT.p\", 'rb')) , valuesS, toRemoveS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morpho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTMbaseMulti/1/256/GRU/epoch4.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "test_loss: 0.6901 - test_acc: 82.6615\n",
      "MAPs: 0.8881 - MAPc: 0.4844\n",
      "acc: 0.8266 - kappa: 0.8064\n",
      "accT3: 0.9402 - accT5: 0.9602\n",
      "f1micro: 0.8266 - f1macro: 0.4278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trianam/miniconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] =  calculatePred(configurationsMulticlass.configTMbaseMultiBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionGRU-Amorpho.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTMImulti/2/256/epoch10.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "test_loss: 4.4054 - test_acc: 73.1654\n",
      "MAPs: 0.8169 - MAPc: 0.3776\n",
      "acc: 0.7317 - kappa: 0.6964\n",
      "accT3: 0.9012 - accT5: 0.9305\n",
      "f1micro: 0.7317 - f1macro: 0.2413\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] =  calculatePred(configurationsMulticlass.configTMImultiBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionMAXi-Amorpho.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confHM/64/1/1024/best.pt\n",
      "         reprocessed line 84127/84127           \n",
      "test_loss: 0.6817 - test_acc: 83.1298\n",
      "MAPs: 0.8894 - MAPc: 0.4515\n",
      "acc: 0.8313 - kappa: 0.8117\n",
      "accT3: 0.9382 - accT5: 0.9582\n",
      "f1micro: 0.8313 - f1macro: 0.4331\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] = calculatePred(configurationsMulticlass.configHMbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionMAXh-Amorpho.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confHSM/64/1/1024/128/best.pt\n",
      "         reprocessed line 84127/84127           \n",
      "test_loss: 0.7179 - test_acc: 83.1772\n",
      "MAPs: 0.8894 - MAPc: 0.4915\n",
      "acc: 0.8318 - kappa: 0.8119\n",
      "accT3: 0.9388 - accT5: 0.9566\n",
      "f1micro: 0.8318 - f1macro: 0.4668\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] = calculatePred(configurationsMulticlass.configHSMbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionATTh-Amorpho.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTSMmulti1/256/1/128/256/epoch12.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "test_loss: 0.6890 - test_acc: 84.2442\n",
      "MAPs: 0.8973 - MAPc: 0.5295\n",
      "acc: 0.8424 - kappa: 0.8240\n",
      "accT3: 0.9445 - accT5: 0.9632\n",
      "f1micro: 0.8424 - f1macro: 0.5079\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] = calculatePred(configurationsMulticlass.configTSMmulti1best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionATT-Amorpho.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modelsPytorchMulticlass/confTMmulti1/128/1/128/epoch8.pt\n",
      "         processed line 84127/84127           \n",
      "         reprocessed line 84127/84127           \n",
      "test_loss: 0.6612 - test_acc: 83.9419\n",
      "MAPs: 0.8962 - MAPc: 0.4530\n",
      "acc: 0.8394 - kappa: 0.8207\n",
      "accT3: 0.9452 - accT5: 0.9634\n",
      "f1micro: 0.8394 - f1macro: 0.4581\n"
     ]
    }
   ],
   "source": [
    "p['y'], p['yp'] = calculatePred(configurationsMulticlass.configTMmulti1best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(p, open(\"predictionMAX-Amorpho.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfM['SVM'] = calculateMetrics(pickle.load(open(\"predictionsSVM-Amorpho.p\", 'rb')), values<, toRemoveM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfM['XGBoost'] = calculateMetrics(pickle.load(open(\"predictionsXGBoost-Amorpho.p\", 'rb')), values<, toRemoveM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfM['BERT'] = calculateMetrics(pickle.load(open(\"../../bert/predictionsBERTmorpho.p\", 'rb')), values<, toRemoveM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
