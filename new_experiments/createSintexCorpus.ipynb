{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import configurationsMulticlass\n",
    "import funPytorch as fun\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "keepWords = [1,2,3,4,5,6,7,8,9,10,20,30,40,50,100]\n",
    "corpusDir = \"corpusSintex/mod-{}/keep-{}\"\n",
    "corpusFile = \"corpusSintex.p\"\n",
    "\n",
    "conf = {\n",
    "    'max': configurationsMulticlass.configTmulti1best,\n",
    "    'soft': configurationsMulticlass.configTSmulti1best,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusKey = conf['max'].corpusKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         processed line 85170/85170           \n",
      "         reprocessed line 85170/85170           \n"
     ]
    }
   ],
   "source": [
    "X, y, train, valid, test, allText = fun.processData(conf['max'], getText=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {m:fun.loadModel(conf[m], device)[0] for m in conf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = pickle.load(open(conf['max'].fileValues, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train':train,\n",
    "    'valid':valid,\n",
    "    'test':test,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "att ={m:{d:fun.getAttention(conf[m], model[m], X, y, dataset[d])[1] for d in dataset} for m in model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model:\n",
    "    for d in dataset:\n",
    "        if np.min(att[m][d]) < 0.:\n",
    "            att[m][d] = att[m][d]/2 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51101, 100, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att['max']['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51101, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att['soft']['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset:\n",
    "    att['max'][d] = np.sum(att['max'][d], axis=2)/512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51101, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att['max']['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = {d:[values[currY] for currY in y[dataset[d]]] for d in dataset}\n",
    "text = {d:[allText[c] for c in dataset[d]] for d in dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model:\n",
    "    for k in keepWords:\n",
    "        os.makedirs(corpusDir.format(m,k))\n",
    "        currWordIndices = {d:np.argsort(att[m][d])[:,-k:] for d in dataset}\n",
    "        currCorpus = {}\n",
    "        for d in dataset:\n",
    "            currCorpus[d] = {\n",
    "                'text': np.array([' '.join([text[d][i][j] for j in currWordIndices[d][i] if j<len(text[d][i])]) for i in range(len(text[d]))]),\n",
    "                corpusKey: np.array(i[d]),\n",
    "            }\n",
    "        pickle.dump(currCorpus, open(os.path.join(corpusDir.format(m,k), corpusFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
